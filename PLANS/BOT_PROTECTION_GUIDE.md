# Bot Protection Bypass Guide

This guide explains the various techniques implemented in the Dynamic Web Scraping Toolkit to handle bot protection and anti-bot measures.

## üõ°Ô∏è Types of Bot Protection

### 1. Cloudflare Protection
- **Detection**: "Just a moment..." or "Checking your browser" messages
- **Types**: 
  - Browser integrity check
  - I'm Under Attack Mode (IUAM)
  - JavaScript challenge
  - CAPTCHA challenge

### 2. Other Protection Services
- **Imperva Incapsula**
- **Akamai Bot Manager**
- **DataDome**
- **PerimeterX**
- **Custom protection scripts**

### 3. Basic Detection Methods
- User agent checking
- IP-based blocking
- Behavioral analysis
- JavaScript fingerprinting

## ü•∑ Stealth Techniques Implemented

### 1. User Agent Spoofing
```python
# Realistic user agents from real browsers
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36...",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36...",
    # ... more realistic UAs
]
```

### 2. Browser Fingerprint Masking
```javascript
// Remove automation indicators
Object.defineProperty(navigator, 'webdriver', {
    get: () => undefined,
});

// Mock realistic browser properties
window.chrome = { runtime: {} };
```

### 3. Realistic Headers
```python
headers = {
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9...',
    'Accept-Language': 'en-US,en;q=0.9',
    'Accept-Encoding': 'gzip, deflate, br',
    'DNT': '1',
    'Connection': 'keep-alive',
    # ... full browser-like headers
}
```

### 4. Human-like Behavior
- Random delays between actions
- Mouse movements and scrolling
- Realistic viewport sizes
- Geolocation spoofing

### 5. Browser Launch Arguments
```python
launch_args = [
    '--disable-blink-features=AutomationControlled',
    '--disable-extensions',
    '--no-sandbox',
    '--disable-infobars',
    # ... more stealth arguments
]
```

## üöÄ Usage Examples

### Basic Stealth Mode
```python
from scraping import DynamicWebScraper

# Enable stealth mode (default)
scraper = DynamicWebScraper(
    headless=True,
    stealth_mode=True,
    timeout=30000
)

results = scraper.comprehensive_scrape("https://protected-site.com")
```

### Advanced Configuration
```python
# With proxy and retry logic
scraper = DynamicWebScraper(
    headless=True,
    stealth_mode=True,
    use_proxy="http://proxy:8080",
    timeout=30000
)

results = scraper.comprehensive_scrape(
    "https://protected-site.com",
    max_retries=5
)
```

### CLI Usage
```bash
# Basic stealth analysis
uv run python -m scraping.cli https://protected-site.com --stealth

# With proxy and retries
uv run python -m scraping.cli https://protected-site.com \
    --stealth \
    --proxy http://proxy:8080 \
    --retries 5 \
    --headed
```

## üîç Detection and Bypass Process

### 1. Automatic Detection
The toolkit automatically detects various protection types:

```python
def _detect_bot_protection(self, page, title: str) -> str:
    protection_indicators = []
    
    # Check title for protection messages
    protection_titles = [
        "just a moment", "checking your browser", "cloudflare", 
        "access denied", "blocked", "captcha"
    ]
    
    # Check for protection elements
    protection_selectors = [
        '.cf-browser-verification',  # Cloudflare
        '#challenge-form',          # Cloudflare
        '.grecaptcha-badge',        # reCAPTCHA
    ]
    
    return "; ".join(protection_indicators)
```

### 2. Cloudflare Bypass
```python
def wait_for_cloudflare(page, max_wait: int = 30):
    # Wait for protection to complete automatically
    # Most challenges solve themselves in 5-10 seconds
    
def bypass_cloudflare_iuam(page):
    # Handle "I'm Under Attack Mode"
    # Wait for auto-completion or manual solving
```

### 3. Retry Logic
```python
# Automatic retry with exponential backoff
for attempt in range(max_retries):
    try:
        # Attempt scraping with different configurations
        results = scrape_with_stealth()
        if successful:
            break
    except BotProtectionException:
        wait_time = 2 ** attempt  # Exponential backoff
        time.sleep(wait_time)
```

## üìä Testing Bot Protection Bypass

### Test Script
```bash
# Test stealth capabilities
uv run python test_stealth.py

# Test specific site
uv run python test_stealth.py hims.com
```

### What the Test Shows
1. **Before/After Comparison**: Normal vs stealth mode
2. **Protection Detection**: What protection was found
3. **Bypass Success**: Whether stealth mode helped
4. **Performance Metrics**: Elements found, content extracted

## üõ†Ô∏è Advanced Techniques

### 1. Residential Proxies
```python
# Use rotating residential proxies
proxy_list = [
    "http://user:pass@proxy1:8080",
    "http://user:pass@proxy2:8080",
    # ... more proxies
]

scraper = DynamicWebScraper(use_proxy=random.choice(proxy_list))
```

### 2. Session Management
```python
# Maintain sessions across requests
context = browser.new_context(
    storage_state="session.json"  # Saved cookies/localStorage
)
```

### 3. Browser Profiles
```python
# Use real browser profiles
context = browser.new_context(
    user_data_dir="/path/to/chrome/profile"
)
```

### 4. CAPTCHA Handling
```python
# For sites with CAPTCHA
if page.query_selector('.captcha'):
    print("CAPTCHA detected - manual intervention required")
    input("Please solve CAPTCHA and press Enter...")
```

## ‚ö†Ô∏è Legal and Ethical Considerations

### ‚úÖ Legitimate Use Cases
- **Academic research**
- **Your own websites**
- **Publicly available data**
- **APIs with proper authentication**
- **Testing your own protection systems**

### ‚ùå Avoid These Practices
- Circumventing paywalls
- Ignoring robots.txt
- Overloading servers
- Accessing private/protected content
- Commercial scraping without permission

### Best Practices
1. **Respect rate limits**: Add delays between requests
2. **Check robots.txt**: Honor site policies
3. **Use APIs when available**: Prefer official APIs
4. **Cache responses**: Don't re-request same data
5. **Handle errors gracefully**: Don't hammer failing endpoints

## üîß Troubleshooting

### Common Issues

#### 1. Still Getting Blocked
- Try different user agents
- Use residential proxies
- Increase delays between requests
- Reduce request frequency

#### 2. Timeouts
- Increase timeout values
- Add more retry attempts
- Check network connectivity

#### 3. Detection Bypass Failing
- Update user agent strings
- Modify browser fingerprint
- Use different proxy providers
- Implement session rotation

### Debug Mode
```python
# Enable verbose logging
scraper = DynamicWebScraper(
    headless=False,  # Show browser
    stealth_mode=True
)

# Check what's being detected
results = scraper.comprehensive_scrape(url)
protection = results.get('final_structure', {}).get('protection_detected')
print(f"Protection detected: {protection}")
```

## üìà Success Rates

Based on testing, the stealth mode shows:
- **70-80% success rate** against basic bot detection
- **50-60% success rate** against Cloudflare browser checks
- **30-40% success rate** against advanced protection
- **Variable success** depending on site complexity

## üîÑ Continuous Improvement

The bot protection landscape constantly evolves. To stay effective:

1. **Update user agents** regularly
2. **Monitor detection patterns**
3. **Test against new protection services**
4. **Contribute improvements** to the toolkit

---

*Remember: Always use these techniques responsibly and in compliance with website terms of service and applicable laws.* 